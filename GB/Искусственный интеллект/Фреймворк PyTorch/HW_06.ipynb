{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самостоятельно обучить классификатор текстов на примере 20newsgroups\n",
    "\n",
    "На примере 20 newsgroups попробовать разные параметры для сверток для классификации текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(df,i,batch_size):\n",
    "    batches = []\n",
    "    results = []\n",
    "    texts = df.data[i*batch_size:i*batch_size+batch_size]\n",
    "    categories = df.target[i*batch_size:i*batch_size+batch_size]\n",
    "    for text in texts:\n",
    "        layer = np.zeros(total_words,dtype=float)\n",
    "        for word in text.split(' '):\n",
    "            layer[word2index[word.lower()]] += 1\n",
    "            \n",
    "        batches.append(layer)\n",
    "        \n",
    "    for category in categories:\n",
    "        index_y = -1\n",
    "        if category == 0:\n",
    "            index_y = 0\n",
    "        elif category == 1:\n",
    "            index_y = 1\n",
    "        else:\n",
    "            index_y = 2\n",
    "        results.append(index_y)\n",
    "            \n",
    "     \n",
    "    return np.array(batches),np.array(results)\n",
    "\n",
    "class pyNet(nn.Module):\n",
    "     def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(pyNet, self).__init__()\n",
    "        self.layer_1 = nn.Linear(input_size,hidden_size, bias=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer_2 = nn.Linear(hidden_size, hidden_size, bias=True)\n",
    "        self.output_layer = nn.Linear(hidden_size, num_classes, bias=True)\n",
    " \n",
    "     def forward(self, x):\n",
    "        out = self.layer_1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer_2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.output_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism',\n",
    " 'comp.graphics',\n",
    " 'comp.os.ms-windows.misc',\n",
    " 'comp.sys.ibm.pc.hardware',\n",
    " 'comp.sys.mac.hardware',\n",
    " 'comp.windows.x',\n",
    " 'misc.forsale',\n",
    " 'rec.autos',\n",
    " 'rec.motorcycles',\n",
    " 'rec.sport.baseball',\n",
    " 'rec.sport.hockey',\n",
    " 'sci.crypt',\n",
    " 'sci.electronics',\n",
    " 'sci.med',\n",
    " 'sci.space',\n",
    " 'soc.religion.christian',\n",
    " 'talk.politics.guns',\n",
    " 'talk.politics.mideast',\n",
    " 'talk.politics.misc',\n",
    " 'talk.religion.misc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words in train: 11314\n",
      "words in test: 7532\n"
     ]
    }
   ],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories)\n",
    "\n",
    "print('words in train:',len(newsgroups_train.data))\n",
    "print('words in test:',len(newsgroups_test.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Counter()\n",
    "\n",
    "for text in newsgroups_train.data:\n",
    "    for word in text.split(' '):\n",
    "        vocab[word.lower()]+=1\n",
    "        \n",
    "for text in newsgroups_test.data:\n",
    "    for word in text.split(' '):\n",
    "        vocab[word.lower()]+=1\n",
    "        \n",
    "total_words = len(vocab)\n",
    "\n",
    "def get_word_2_index(vocab):\n",
    "    word2index = {}\n",
    "    for i,word in enumerate(vocab):\n",
    "        word2index[word.lower()] = i\n",
    "        \n",
    "    return word2index\n",
    "\n",
    "word2index = get_word_2_index(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "num_epochs = 10\n",
    "batch_size = 150\n",
    "display_step = 1\n",
    "\n",
    "hidden_size = 100\n",
    "input_size = total_words\n",
    "num_classes = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = pyNet(input_size, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0669, grad_fn=<NllLossBackward0>) tensor(0.7269, grad_fn=<NllLossBackward0>)\n",
      "Validation loss decreased (inf --> 0.726942).  Saving model ...\n",
      "tensor(5.1326, grad_fn=<NllLossBackward0>) tensor(0.8325, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3059, grad_fn=<NllLossBackward0>) tensor(0.9914, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2347, grad_fn=<NllLossBackward0>) tensor(0.6182, grad_fn=<NllLossBackward0>)\n",
      "Validation loss decreased (0.726942 --> 0.618227).  Saving model ...\n",
      "tensor(3.1294, grad_fn=<NllLossBackward0>) tensor(1.0912, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2695, grad_fn=<NllLossBackward0>) tensor(0.3826, grad_fn=<NllLossBackward0>)\n",
      "Validation loss decreased (0.618227 --> 0.382610).  Saving model ...\n",
      "tensor(0.2595, grad_fn=<NllLossBackward0>) tensor(1.3062, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.2526, grad_fn=<NllLossBackward0>) tensor(0.2520, grad_fn=<NllLossBackward0>)\n",
      "Validation loss decreased (0.382610 --> 0.252047).  Saving model ...\n",
      "tensor(0.2146, grad_fn=<NllLossBackward0>) tensor(0.6626, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.5918, grad_fn=<NllLossBackward0>) tensor(0.4146, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)  \n",
    "valid_loss_min = np.inf\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_batch = int(len(newsgroups_train.data)/batch_size)\n",
    "    net.train()\n",
    "    for i in range(total_batch):\n",
    "        batch_x,batch_y = get_batch(newsgroups_train,i,batch_size)\n",
    "        articles = Variable(torch.FloatTensor(batch_x))\n",
    "        labels = Variable(torch.LongTensor(batch_y))\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(articles)\n",
    "        loss_train = criterion(outputs, labels)\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    total_batch = int(len(newsgroups_test.data)/batch_size)\n",
    "\n",
    "    net.eval()\n",
    "    for i in range(total_batch):\n",
    "        batch_x,batch_y = get_batch(newsgroups_test,i,batch_size)\n",
    "        articles = Variable(torch.FloatTensor(batch_x))\n",
    "        labels = Variable(torch.LongTensor(batch_y))\n",
    "        outputs = net(articles)\n",
    "        loss_test = criterion(outputs, labels)\n",
    "        loss_test.backward()\n",
    "        optimizer.step()\n",
    "    print(loss_train, loss_test)\n",
    "    \n",
    "    if loss_test <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        loss_test))\n",
    "        torch.save(net.state_dict(), 'wieghts.pt')\n",
    "        valid_loss_min = loss_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
