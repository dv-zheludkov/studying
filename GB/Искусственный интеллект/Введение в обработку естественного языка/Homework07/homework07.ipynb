{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тема “Свёртки”\n",
    "\n",
    "Берем отызывы за лето (из архива с материалами или предыдущего занятия)\n",
    "1. Учим conv сеть для классификации\n",
    "2. Рассмотреть 2-а варианта сеточек\n",
    "- Инициализировать tf.keras.layers.Embedding предобученными векторами взять к примеру с https://rusvectores.org/ru/\n",
    "- Инициализировать слой tf.keras.layers.Embedding по умолчанию (ну то есть вам ничего не делать с весами)\n",
    "\n",
    "Сравнить две архитектуры с предобученными весами и когда tf.keras.layers.Embedding обучается сразу со всей сеточкой, что получилось лучше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stop_words in /usr/local/lib/python3.10/site-packages (2018.7.23)\n",
      "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.10/site-packages (0.9.1)\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/site-packages (2.10.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/site-packages (1.1.3)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/site-packages (3.7)\n",
      "Requirement already satisfied: xlrd in /usr/local/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.10/site-packages (0.18.0)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.10/site-packages (from pymorphy2) (0.7.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.10/site-packages (from pymorphy2) (2.4.417127.4579844)\n",
      "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.10/site-packages (from pymorphy2) (0.6.2)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in /usr/local/lib/python3.10/site-packages (from tensorflow) (2.10.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/site-packages (from tensorflow) (65.4.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.10/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/site-packages (from tensorflow) (0.27.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/site-packages (from tensorflow) (22.10.26)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/site-packages (from tensorflow) (1.50.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /usr/local/lib/python3.10/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/site-packages (from tensorflow) (1.3.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in /usr/local/lib/python3.10/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/site-packages (from tensorflow) (1.23.4)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.10/site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/site-packages (from tensorflow) (4.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/site-packages (from scikit-learn) (1.9.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.10/site-packages (from tensorflow-addons) (2.13.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.14.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.10/site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2022.9.24)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install stop_words pymorphy2 tensorflow scikit-learn nltk xlrd tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 11:26:06.404047: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from string import punctuation\n",
    "from stop_words import get_stop_words\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D, GlobalMaxPool1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import TensorBoard \n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/dv/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 300\n",
    "max_len = 40\n",
    "num_classes = 1\n",
    "\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 512\n",
    "print_batch_n = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  pd.read_excel('отзывы за лето.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>It just works!</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>В целом удобноное приложение...из минусов хотя...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Отлично все</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Стал зависать на 1% работы антивируса. Дальше ...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Очень удобно, работает быстро.</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                                            Content        Date\n",
       "0       5                                     It just works!  2017-08-14\n",
       "1       4  В целом удобноное приложение...из минусов хотя...  2017-08-14\n",
       "2       5                                        Отлично все  2017-08-14\n",
       "3       5  Стал зависать на 1% работы антивируса. Дальше ...  2017-08-14\n",
       "4       5                     Очень удобно, работает быстро.  2017-08-14"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(punctuation)\n",
    "morpher = MorphAnalyzer()\n",
    "\n",
    "def preprocess_text(txt):\n",
    "    txt = str(txt)\n",
    "    txt = \"\".join(c for c in txt if c not in exclude)\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(\"\\sне\", \"не\", txt)\n",
    "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
    "    return \" \".join(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Date', axis=1, inplace=True)\n",
    "df_train, df_test = train_test_split(df, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3517</th>\n",
       "      <td>5</td>\n",
       "      <td>Наконец-то исправили эту чушь с неоргинальной ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12399</th>\n",
       "      <td>5</td>\n",
       "      <td>Удобно в использовании</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3833</th>\n",
       "      <td>5</td>\n",
       "      <td>Отлично</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13250</th>\n",
       "      <td>5</td>\n",
       "      <td>Класс</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17941</th>\n",
       "      <td>5</td>\n",
       "      <td>Удобно</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Rating                                            Content\n",
       "3517        5  Наконец-то исправили эту чушь с неоргинальной ...\n",
       "12399       5                             Удобно в использовании\n",
       "3833        5                                            Отлично\n",
       "13250       5                                              Класс\n",
       "17941       5                                             Удобно"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>5</td>\n",
       "      <td>Всё отлично!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19916</th>\n",
       "      <td>5</td>\n",
       "      <td>Мне нравится. Удобно. Еще ни разу не подвел!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2112</th>\n",
       "      <td>3</td>\n",
       "      <td>Иногда слишком долго приходится ждать пока зап...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15154</th>\n",
       "      <td>5</td>\n",
       "      <td>Отличное приложение. Легко отслеживать свои ра...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18329</th>\n",
       "      <td>5</td>\n",
       "      <td>Все грамотно</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Rating                                            Content\n",
       "1457        5                                     Всё отлично!!!\n",
       "19916       5       Мне нравится. Удобно. Еще ни разу не подвел!\n",
       "2112        3  Иногда слишком долго приходится ждать пока зап...\n",
       "15154       5  Отличное приложение. Легко отслеживать свои ра...\n",
       "18329       5                                       Все грамотно"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Content'] = df_train['Content'].apply(preprocess_text)\n",
    "df_test['Content'] = df_test['Content'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = \" \".join(df_train[\"Content\"])\n",
    "train_corpus = train_corpus.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['приложение',\n",
       " 'удобно',\n",
       " 'работать',\n",
       " 'удобный',\n",
       " 'отлично',\n",
       " 'нравиться',\n",
       " 'хороший',\n",
       " 'отличный',\n",
       " 'телефон',\n",
       " 'супер']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(train_corpus)\n",
    "tokens_filtered = [word for word in tokens if word.isalnum()]\n",
    "dist = FreqDist(tokens_filtered)\n",
    "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words-1)]\n",
    "tokens_filtered_top[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top, 1)).items()}\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_sequence(text, maxlen):\n",
    "    result = []\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens_filtered = [word for word in tokens if word.isalnum()]\n",
    "    for word in tokens_filtered:\n",
    "        if word in vocabulary:\n",
    "            result.append(vocabulary[word])\n",
    "    padding = [0]*(maxlen-len(result))\n",
    "    return padding + result[-maxlen:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.asarray([text_to_sequence(text, max_len) for text in df_train[\"Content\"]], dtype=np.int32)\n",
    "x_test = np.asarray([text_to_sequence(text, max_len) for text in df_test[\"Content\"]], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "train_enc_labels = le.fit_transform(df_train['Rating']) \n",
    "test_enc_labels = le.transform(df_test['Rating'])\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "y_train = tf.keras.utils.to_categorical(train_enc_labels, num_classes=num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(test_enc_labels, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 11:26:27.622023: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 40, 128)           38400     \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 38, 128)           49280     \n",
      "                                                                 \n",
      " activation (Activation)     (None, 38, 128)           0         \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 128)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                1290      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 55        \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89,025\n",
      "Trainable params: 89,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))\n",
    "model.add(Conv1D(128, 3))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', tfa.metrics.F1Score(num_classes=num_classes, average='macro')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 2s 54ms/step - loss: 1.2657 - accuracy: 0.6787 - f1_score: 0.1920 - val_loss: 0.9834 - val_accuracy: 0.7011 - val_f1_score: 0.1649\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.9023 - accuracy: 0.7182 - f1_score: 0.2180 - val_loss: 0.8232 - val_accuracy: 0.7365 - val_f1_score: 0.2664\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.7400 - accuracy: 0.7599 - f1_score: 0.2926 - val_loss: 0.7346 - val_accuracy: 0.7437 - val_f1_score: 0.2895\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.6765 - accuracy: 0.7718 - f1_score: 0.3281 - val_loss: 0.7098 - val_accuracy: 0.7451 - val_f1_score: 0.3092\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.6514 - accuracy: 0.7765 - f1_score: 0.3488 - val_loss: 0.6998 - val_accuracy: 0.7487 - val_f1_score: 0.3292\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.6382 - accuracy: 0.7796 - f1_score: 0.3659 - val_loss: 0.6985 - val_accuracy: 0.7502 - val_f1_score: 0.3338\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.6267 - accuracy: 0.7846 - f1_score: 0.3789 - val_loss: 0.6963 - val_accuracy: 0.7516 - val_f1_score: 0.3463\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.6173 - accuracy: 0.7884 - f1_score: 0.3983 - val_loss: 0.6985 - val_accuracy: 0.7502 - val_f1_score: 0.3461\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 0.6084 - accuracy: 0.7921 - f1_score: 0.4075 - val_loss: 0.6978 - val_accuracy: 0.7502 - val_f1_score: 0.3443\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.5995 - accuracy: 0.7942 - f1_score: 0.4183 - val_loss: 0.7008 - val_accuracy: 0.7480 - val_f1_score: 0.3459\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.5912 - accuracy: 0.7966 - f1_score: 0.4230 - val_loss: 0.7054 - val_accuracy: 0.7487 - val_f1_score: 0.3362\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.5814 - accuracy: 0.8003 - f1_score: 0.4390 - val_loss: 0.7055 - val_accuracy: 0.7495 - val_f1_score: 0.3403\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 1s 44ms/step - loss: 0.5726 - accuracy: 0.8042 - f1_score: 0.4483 - val_loss: 0.7067 - val_accuracy: 0.7487 - val_f1_score: 0.3589\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.5659 - accuracy: 0.8064 - f1_score: 0.4562 - val_loss: 0.7087 - val_accuracy: 0.7502 - val_f1_score: 0.3652\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.5567 - accuracy: 0.8118 - f1_score: 0.4743 - val_loss: 0.7176 - val_accuracy: 0.7473 - val_f1_score: 0.3524\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.5463 - accuracy: 0.8155 - f1_score: 0.4813 - val_loss: 0.7174 - val_accuracy: 0.7516 - val_f1_score: 0.3591\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.5379 - accuracy: 0.8182 - f1_score: 0.4884 - val_loss: 0.7205 - val_accuracy: 0.7531 - val_f1_score: 0.3693\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 1s 44ms/step - loss: 0.5275 - accuracy: 0.8258 - f1_score: 0.5191 - val_loss: 0.7305 - val_accuracy: 0.7538 - val_f1_score: 0.3642\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.5216 - accuracy: 0.8233 - f1_score: 0.5102 - val_loss: 0.7361 - val_accuracy: 0.7466 - val_f1_score: 0.3605\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.5102 - accuracy: 0.8287 - f1_score: 0.5281 - val_loss: 0.7438 - val_accuracy: 0.7473 - val_f1_score: 0.3596\n"
     ]
    }
   ],
   "source": [
    "tensorboard = TensorBoard(log_dir='./logs', write_graph=True, write_images=True)\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 9ms/step - loss: 0.6900 - accuracy: 0.7633 - f1_score: 0.3610\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!wget http://vectors.nlpl.eu/repository/20/220.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!unzip 220.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install -U gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_model = gensim.models.KeyedVectors.load_word2vec_format('model.bin', binary=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249333"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_model_matrix = [word_model[i][:128] for i in range(300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 40, 128)           38400     \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 38, 128)           49280     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 38, 128)           0         \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Glo  (None, 128)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 55        \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89,025\n",
      "Trainable params: 89,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "initializer = tf.keras.initializers.Constant(word_model_matrix)\n",
    "\n",
    "model_w = Sequential()\n",
    "model_w.add(Embedding(input_dim=max_words, output_dim=128, embeddings_initializer =initializer, input_length=max_len))\n",
    "model_w.add(Conv1D(128, 3))\n",
    "model_w.add(Activation(\"relu\"))\n",
    "model_w.add(GlobalMaxPool1D())\n",
    "model_w.add(Dense(10))\n",
    "model_w.add(Activation(\"relu\"))\n",
    "model_w.add(Dense(num_classes))\n",
    "model_w.add(Activation('softmax'))\n",
    "model_w.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', tfa.metrics.F1Score(num_classes=num_classes, average='macro')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 2s 52ms/step - loss: 1.3375 - accuracy: 0.6745 - f1_score: 0.2649 - val_loss: 0.8896 - val_accuracy: 0.7119 - val_f1_score: 0.2662\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.8429 - accuracy: 0.7187 - f1_score: 0.2692 - val_loss: 0.8394 - val_accuracy: 0.7054 - val_f1_score: 0.2513\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.7931 - accuracy: 0.7280 - f1_score: 0.2789 - val_loss: 0.8255 - val_accuracy: 0.7184 - val_f1_score: 0.2575\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.7603 - accuracy: 0.7315 - f1_score: 0.2790 - val_loss: 0.8050 - val_accuracy: 0.7213 - val_f1_score: 0.2706\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.7348 - accuracy: 0.7351 - f1_score: 0.2848 - val_loss: 0.7946 - val_accuracy: 0.7235 - val_f1_score: 0.2743\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.7136 - accuracy: 0.7393 - f1_score: 0.2929 - val_loss: 0.7982 - val_accuracy: 0.7227 - val_f1_score: 0.2729\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.6975 - accuracy: 0.7441 - f1_score: 0.3003 - val_loss: 0.7790 - val_accuracy: 0.7256 - val_f1_score: 0.2824\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 1s 44ms/step - loss: 0.6821 - accuracy: 0.7472 - f1_score: 0.3083 - val_loss: 0.7716 - val_accuracy: 0.7242 - val_f1_score: 0.2769\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.6665 - accuracy: 0.7519 - f1_score: 0.3164 - val_loss: 0.7686 - val_accuracy: 0.7256 - val_f1_score: 0.2933\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 1s 44ms/step - loss: 0.6560 - accuracy: 0.7561 - f1_score: 0.3278 - val_loss: 0.7677 - val_accuracy: 0.7278 - val_f1_score: 0.2902\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 1s 44ms/step - loss: 0.6390 - accuracy: 0.7603 - f1_score: 0.3382 - val_loss: 0.7711 - val_accuracy: 0.7329 - val_f1_score: 0.2949\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 0.6276 - accuracy: 0.7637 - f1_score: 0.3427 - val_loss: 0.7656 - val_accuracy: 0.7300 - val_f1_score: 0.2886\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 1s 44ms/step - loss: 0.6178 - accuracy: 0.7675 - f1_score: 0.3540 - val_loss: 0.7641 - val_accuracy: 0.7314 - val_f1_score: 0.2945\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 1s 44ms/step - loss: 0.6102 - accuracy: 0.7693 - f1_score: 0.3559 - val_loss: 0.7519 - val_accuracy: 0.7314 - val_f1_score: 0.3021\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 1s 44ms/step - loss: 0.5977 - accuracy: 0.7742 - f1_score: 0.3678 - val_loss: 0.7765 - val_accuracy: 0.7329 - val_f1_score: 0.2904\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 0.5867 - accuracy: 0.7765 - f1_score: 0.3694 - val_loss: 0.7567 - val_accuracy: 0.7321 - val_f1_score: 0.3068\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 1s 44ms/step - loss: 0.5800 - accuracy: 0.7787 - f1_score: 0.3756 - val_loss: 0.7676 - val_accuracy: 0.7336 - val_f1_score: 0.2901\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 1s 43ms/step - loss: 0.5730 - accuracy: 0.7811 - f1_score: 0.3829 - val_loss: 0.7500 - val_accuracy: 0.7357 - val_f1_score: 0.3077\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 0.5681 - accuracy: 0.7850 - f1_score: 0.3902 - val_loss: 0.7592 - val_accuracy: 0.7422 - val_f1_score: 0.3146\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 1s 44ms/step - loss: 0.5551 - accuracy: 0.7897 - f1_score: 0.3998 - val_loss: 0.8031 - val_accuracy: 0.7394 - val_f1_score: 0.3124\n"
     ]
    }
   ],
   "source": [
    "tensorboard = TensorBoard(log_dir='./logs', write_graph=True, write_images=True)\n",
    "\n",
    "history_w = model_w.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 9ms/step - loss: 0.7780 - accuracy: 0.7495 - f1_score: 0.3144\n"
     ]
    }
   ],
   "source": [
    "score_p = model_w.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.690024197101593, 0.7632737159729004, 0.36102837324142456]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7779568433761597, 0.7494866251945496, 0.31437259912490845]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предобученная модель показала результат ниже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "gJABxhalLVQu",
    "IaQMCGHFLVQ6",
    "5AJk1B39LVRP",
    "RJlvqWuALVRs",
    "rck5OVqhLVSA",
    "mV3fmzp-LVSU",
    "H5THCOjMLVSg",
    "02s2Vh7MLVSj",
    "b1khxRFDLVSm",
    "sfUmWcAQLVSt",
    "BxvtN-3zLVS5",
    "gyrHhYkgLVTB"
   ],
   "name": "sem1_intro_common.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
