{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DUotKHRULVPD"
   },
   "source": [
    "# Инструменты для работы с языком "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание\n",
    "\n",
    "все материалы для выполения дз в `sem2.ipynb`\n",
    "\n",
    "\n",
    "### Задание 1.\n",
    "\n",
    "**Задание**: обучите три классификатора: \n",
    "\n",
    "1) на токенах с высокой частотой \n",
    "\n",
    "2) на токенах со средней частотой \n",
    "\n",
    "3) на токенах с низкой частотой\n",
    "\n",
    "\n",
    "Сравните полученные результаты, оцените какие токены наиболее важные для классификации.\n",
    "\n",
    "\n",
    "### Задание 2.\n",
    "\n",
    "найти фичи с наибольшей значимостью, и вывести их\n",
    "\n",
    "\n",
    "### Задание 3.\n",
    "\n",
    "1) сравнить count/tf-idf/hashing векторайзеры/полносвязанную сетку (построить classification_report)\n",
    "\n",
    "2) подобрать оптимальный размер для hashing векторайзера \n",
    "\n",
    "3) убедиться что для сетки нет переобучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2zHB70n5LVPN",
    "outputId": "76e9cc41-c912-464c-a06e-e02879e69c08",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-10-13 12:36:05--  https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv\n",
      "Распознаётся www.dropbox.com (www.dropbox.com)… 162.125.70.18\n",
      "Подключение к www.dropbox.com (www.dropbox.com)|162.125.70.18|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 302 Found\n",
      "Адрес: /s/raw/fnpq3z4bcnoktiv/positive.csv [переход]\n",
      "--2022-10-13 12:36:05--  https://www.dropbox.com/s/raw/fnpq3z4bcnoktiv/positive.csv\n",
      "Повторное использование соединения с www.dropbox.com:443.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 302 Found\n",
      "Адрес: https://uc6ab235df79b91cfce871b25811.dl.dropboxusercontent.com/cd/0/inline/BuvBLbKZuG5u5y5ewNxYzCTCX64RH2RF3ftwyViUg0jT9dx1ZMnTrUFoPu7I6bUPWrA1Ow6n65UIpPME2ZZobZLNxNYoKpHklySK0zjiaEAMfL2mDG22tDhjTYtGk9qTymJ9tWy7Tm9ihnEl5B2QZvCOwI-iNl_tNr2gPCucylhQHQ/file# [переход]\n",
      "--2022-10-13 12:36:06--  https://uc6ab235df79b91cfce871b25811.dl.dropboxusercontent.com/cd/0/inline/BuvBLbKZuG5u5y5ewNxYzCTCX64RH2RF3ftwyViUg0jT9dx1ZMnTrUFoPu7I6bUPWrA1Ow6n65UIpPME2ZZobZLNxNYoKpHklySK0zjiaEAMfL2mDG22tDhjTYtGk9qTymJ9tWy7Tm9ihnEl5B2QZvCOwI-iNl_tNr2gPCucylhQHQ/file\n",
      "Распознаётся uc6ab235df79b91cfce871b25811.dl.dropboxusercontent.com (uc6ab235df79b91cfce871b25811.dl.dropboxusercontent.com)… 162.125.70.15\n",
      "Подключение к uc6ab235df79b91cfce871b25811.dl.dropboxusercontent.com (uc6ab235df79b91cfce871b25811.dl.dropboxusercontent.com)|162.125.70.15|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 200 OK\n",
      "Длина: 26233379 (25M) [text/plain]\n",
      "Сохранение в: «positive.csv.2»\n",
      "\n",
      "positive.csv.2      100%[===================>]  25,02M  15,6MB/s    за 1,6s    \n",
      "\n",
      "2022-10-13 12:36:08 (15,6 MB/s) - «positive.csv.2» сохранён [26233379/26233379]\n",
      "\n",
      "--2022-10-13 12:36:08--  https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv\n",
      "Распознаётся www.dropbox.com (www.dropbox.com)… 162.125.70.18\n",
      "Подключение к www.dropbox.com (www.dropbox.com)|162.125.70.18|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 302 Found\n",
      "Адрес: /s/raw/r6u59ljhhjdg6j0/negative.csv [переход]\n",
      "--2022-10-13 12:36:09--  https://www.dropbox.com/s/raw/r6u59ljhhjdg6j0/negative.csv\n",
      "Повторное использование соединения с www.dropbox.com:443.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 302 Found\n",
      "Адрес: https://uc7b6dece6893af3e38f078dd302.dl.dropboxusercontent.com/cd/0/inline/Buu7n3BghlQv_5TG-s1P5kVEsyplp_Qd0dniK-VyC3T-fy5MmDSkhhKXwaPFfOGArTY4aQK2FyKgb9s9FxiMFQmV3PwgY-4VbLlOw60-EcFFXl9JUmzAlMJiVprWsCMqjbthQmltr9rmGXcrigT7nYYu8MSO42FpdQOP22K-mUb6zA/file# [переход]\n",
      "--2022-10-13 12:36:09--  https://uc7b6dece6893af3e38f078dd302.dl.dropboxusercontent.com/cd/0/inline/Buu7n3BghlQv_5TG-s1P5kVEsyplp_Qd0dniK-VyC3T-fy5MmDSkhhKXwaPFfOGArTY4aQK2FyKgb9s9FxiMFQmV3PwgY-4VbLlOw60-EcFFXl9JUmzAlMJiVprWsCMqjbthQmltr9rmGXcrigT7nYYu8MSO42FpdQOP22K-mUb6zA/file\n",
      "Распознаётся uc7b6dece6893af3e38f078dd302.dl.dropboxusercontent.com (uc7b6dece6893af3e38f078dd302.dl.dropboxusercontent.com)… 162.125.70.15\n",
      "Подключение к uc7b6dece6893af3e38f078dd302.dl.dropboxusercontent.com (uc7b6dece6893af3e38f078dd302.dl.dropboxusercontent.com)|162.125.70.15|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 200 OK\n",
      "Длина: 24450101 (23M) [text/plain]\n",
      "Сохранение в: «negative.csv.2»\n",
      "\n",
      "negative.csv.2      100%[===================>]  23,32M  14,5MB/s    за 1,6s    \n",
      "\n",
      "2022-10-13 12:36:12 (14,5 MB/s) - «negative.csv.2» сохранён [24450101/24450101]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# если у вас линукс / мак / collab или ещё какая-то среда, в которой работает wget, можно так:\n",
    "!wget https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv\n",
    "!wget https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "J5YiZNCPLVPe"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DFLtXAZ-LVPq"
   },
   "outputs": [],
   "source": [
    "# считываем данные и заполняем общий датасет\n",
    "positive = pd.read_csv('positive.csv', sep=';', usecols=[3], names=['text'])\n",
    "positive['label'] = ['positive'] * len(positive)\n",
    "negative = pd.read_csv('negative.csv', sep=';', usecols=[3], names=['text'])\n",
    "negative['label'] = ['negative'] * len(negative)\n",
    "df = pd.concat([positive,negative])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "j1AEISlBLVP0",
    "outputId": "443eadf2-9df4-4507-f2a5-a64f7968182f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@first_timee хоть я и школота, но поверь, у на...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Да, все-таки он немного похож на него. Но мой ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @KatiaCheh: Ну ты идиотка) я испугалась за ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @digger2912: \"Кто то в углу сидит и погибае...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@irina_dyshkant Вот что значит страшилка :D\\nН...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label\n",
       "0  @first_timee хоть я и школота, но поверь, у на...  positive\n",
       "1  Да, все-таки он немного похож на него. Но мой ...  positive\n",
       "2  RT @KatiaCheh: Ну ты идиотка) я испугалась за ...  positive\n",
       "3  RT @digger2912: \"Кто то в углу сидит и погибае...  positive\n",
       "4  @irina_dyshkant Вот что значит страшилка :D\\nН...  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111918</th>\n",
       "      <td>Но не каждый хочет что то исправлять:( http://...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111919</th>\n",
       "      <td>скучаю так :-( только @taaannyaaa вправляет мо...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111920</th>\n",
       "      <td>Вот и в школу, в говно это идти уже надо(</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111921</th>\n",
       "      <td>RT @_Them__: @LisaBeroud Тауриэль, не грусти :...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111922</th>\n",
       "      <td>Такси везет меня на работу. Раздумываю приплат...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text     label\n",
       "111918  Но не каждый хочет что то исправлять:( http://...  negative\n",
       "111919  скучаю так :-( только @taaannyaaa вправляет мо...  negative\n",
       "111920          Вот и в школу, в говно это идти уже надо(  negative\n",
       "111921  RT @_Them__: @LisaBeroud Тауриэль, не грусти :...  negative\n",
       "111922  Такси везет меня на работу. Раздумываю приплат...  negative"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.text, df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from nltk import ngrams\n",
    "import nltk\n",
    "from nltk import collocations \n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package genesis to /Users/dv/nltk_data...\n",
      "[nltk_data]   Package genesis is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/dv/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/dv/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('genesis')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "noise = stopwords.words('russian') + list(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2870536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['first_timee', 'хоть', 'я', 'и', 'школота', 'но', 'поверь', 'у', 'нас', 'то']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [token for tweet in df.text for token in word_tokenize(tweet) if token not in punctuation]\n",
    "print(len(corpus))\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('не', 69472),\n",
       " ('и', 55166),\n",
       " ('в', 52902),\n",
       " ('я', 52818),\n",
       " ('RT', 38070),\n",
       " ('на', 35759),\n",
       " ('http', 32998),\n",
       " ('что', 31541),\n",
       " ('с', 27217),\n",
       " ('а', 26860)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dict = Counter(corpus)\n",
    "freq_dict_sorted= sorted(freq_dict.items(), key=lambda x: -x[1])\n",
    "list(freq_dict_sorted)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dw0GieJSMU-O"
   },
   "source": [
    "## Задание 1.\n",
    "\n",
    "**Задание**: обучите три классификатора: \n",
    "\n",
    "1) на токенах с высокой частотой \n",
    "\n",
    "2) на токенах со средней частотой \n",
    "\n",
    "3) на токенах с низкой частотой\n",
    "\n",
    "Сравните полученные результаты, оцените какие токены наиболее важные для классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "QUQ6kAgPMqNn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 199 350868\n"
     ]
    }
   ],
   "source": [
    "high_tokens = set()\n",
    "medium_tokens = set()\n",
    "low_tokens = set()\n",
    "\n",
    "ht_value = 5000\n",
    "mt_value = 1000\n",
    "\n",
    "for i in freq_dict_sorted:\n",
    "    if i[1] > ht_value:\n",
    "        high_tokens.add(i[0])\n",
    "    elif i[1] < mt_value:\n",
    "        low_tokens.add(i[0])\n",
    "    else:\n",
    "        medium_tokens.add(i[0])\n",
    "\n",
    "print(len(high_tokens),len(medium_tokens),len(low_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyFit_Report (stop_words_list):\n",
    "\n",
    "    vec = CountVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize, stop_words=stop_words_list)\n",
    "    bow = vec.fit_transform(x_train)\n",
    "    clf = LogisticRegression(max_iter=10000, random_state=42)\n",
    "    clf.fit(bow, y_train)\n",
    "    pred = clf.predict(vec.transform(x_test))\n",
    "\n",
    "    print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.59      0.67     37448\n",
      "    positive       0.46      0.68      0.55     19261\n",
      "\n",
      "    accuracy                           0.62     56709\n",
      "   macro avg       0.62      0.63      0.61     56709\n",
      "weighted avg       0.67      0.62      0.63     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# токены с высокой частотой\n",
    "MyFit_Report(noise + list(low_tokens) + list(medium_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.44      0.66      0.53     18560\n",
      "    positive       0.78      0.59      0.67     38149\n",
      "\n",
      "    accuracy                           0.61     56709\n",
      "   macro avg       0.61      0.63      0.60     56709\n",
      "weighted avg       0.67      0.61      0.62     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# токены со средней частотой\n",
    "MyFit_Report(noise + list(high_tokens) + list(low_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.74      0.77     30243\n",
      "    positive       0.73      0.78      0.75     26466\n",
      "\n",
      "    accuracy                           0.76     56709\n",
      "   macro avg       0.76      0.76      0.76     56709\n",
      "weighted avg       0.76      0.76      0.76     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# токены с низкой частотой\n",
    "MyFit_Report(noise + list(high_tokens) + list(medium_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшая точность при выставленных границах получается у низкочастотных токенов. При изменении критериев деления по частоте точность меняется"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2.\n",
    "\n",
    "найти фичи с наибольшей значимостью, и вывести их"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00     28124\n",
      "    positive       1.00      1.00      1.00     28585\n",
      "\n",
      "    accuracy                           1.00     56709\n",
      "   macro avg       1.00      1.00      1.00     56709\n",
      "weighted avg       1.00      1.00      1.00     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize, stop_words=stopwords.words('russian'))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "b_JRuyuRLVSY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('!', 0.5190005113826729), ('\"', 0.5089315628912519), ('#', 0.506744961117283), ('$', 0.49688761924914915), ('%', 0.49888024828510463), ('&', 0.49651730765839636), (\"'\", 0.4967289142816837), ('(', 0.025057750974272163), (')', 0.9131883827963815), ('*', 0.5152621277045971), ('+', 0.4969757886755189), (',', 0.5083849124477596), ('-', 0.510113033204606), ('.', 0.5107302191891939), ('/', 0.546544640180571), (':', 0.5466680773774886), (';', 0.5007318062388686), ('<', 0.4967289142816837), ('=', 0.49651730765839636), ('>', 0.4967289142816837), ('?', 0.5065686222645436), ('@', 0.5687280678551906), ('[', 0.49676418205223155), ('\\\\', 0.49676418205223155), (']', 0.4968699853638752), ('^', 0.503359255144686), ('_', 0.5188065386446595), ('`', 0.4963586026909309), ('{', 0.4967289142816837), ('|', 0.4925673173570333), ('}', 0.4967465481669576), ('~', 0.4968523514786013)]\n"
     ]
    }
   ],
   "source": [
    "tokens_arr = []\n",
    "for i in punctuation:\n",
    "    cool_token = i\n",
    "    pred = ['positive' if cool_token in tweet else 'negative' for tweet in x_test]\n",
    "    tokens_arr.append((i,accuracy_score(pred, y_test)))\n",
    "print(tokens_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фичи с наибольшей значимостью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ")   -    0.9131883827963815\n",
      "@   -    0.5687280678551906\n",
      ":   -    0.5466680773774886\n",
      "/   -    0.546544640180571\n",
      "!   -    0.5190005113826729\n",
      "_   -    0.5188065386446595\n",
      "*   -    0.5152621277045971\n",
      ".   -    0.5107302191891939\n",
      "-   -    0.510113033204606\n",
      "\"   -    0.5089315628912519\n"
     ]
    }
   ],
   "source": [
    "for i in sorted(tokens_arr, key=lambda x: -x[1])[:10]:\n",
    "    print(i[0],'  -   ' ,i[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3.\n",
    "\n",
    "1) сравнить count/tf-idf/hashing векторайзеры/полносвязанную сетку (построить classification_report)\n",
    "\n",
    "2) подобрать оптимальный размер для hashing векторайзера \n",
    "\n",
    "3) убедиться что для сетки нет переобучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.63      0.78     44361\n",
      "    positive       0.43      1.00      0.60     12348\n",
      "\n",
      "    accuracy                           0.71     56709\n",
      "   macro avg       0.72      0.82      0.69     56709\n",
      "weighted avg       0.88      0.71      0.74     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize, stop_words=stopwords.words('russian'))\n",
    "bow = count_vect.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.63      0.78     44361\n",
      "    positive       0.43      1.00      0.60     12348\n",
      "\n",
      "    accuracy                           0.71     56709\n",
      "   macro avg       0.72      0.82      0.69     56709\n",
      "weighted avg       0.88      0.71      0.74     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize, stop_words=stopwords.words('russian'))\n",
    "bow = count_vect.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features = 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.49      0.54      0.52     25377\n",
      "    positive       0.60      0.54      0.57     31332\n",
      "\n",
      "    accuracy                           0.54     56709\n",
      "   macro avg       0.54      0.54      0.54     56709\n",
      "weighted avg       0.55      0.54      0.54     56709\n",
      "\n",
      "==========\n",
      "n_features = 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.57      0.59      0.58     26978\n",
      "    positive       0.62      0.59      0.60     29731\n",
      "\n",
      "    accuracy                           0.59     56709\n",
      "   macro avg       0.59      0.59      0.59     56709\n",
      "weighted avg       0.59      0.59      0.59     56709\n",
      "\n",
      "==========\n",
      "n_features = 1000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.65      0.64     27185\n",
      "    positive       0.67      0.65      0.66     29524\n",
      "\n",
      "    accuracy                           0.65     56709\n",
      "   macro avg       0.65      0.65      0.65     56709\n",
      "weighted avg       0.65      0.65      0.65     56709\n",
      "\n",
      "==========\n",
      "n_features = 10000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.72      0.71     27292\n",
      "    positive       0.73      0.71      0.72     29417\n",
      "\n",
      "    accuracy                           0.71     56709\n",
      "   macro avg       0.71      0.71      0.71     56709\n",
      "weighted avg       0.71      0.71      0.71     56709\n",
      "\n",
      "==========\n",
      "n_features = 100000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.75      0.74     26989\n",
      "    positive       0.77      0.74      0.75     29720\n",
      "\n",
      "    accuracy                           0.74     56709\n",
      "   macro avg       0.74      0.74      0.74     56709\n",
      "weighted avg       0.75      0.74      0.74     56709\n",
      "\n",
      "==========\n",
      "n_features = 200000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.76      0.74     26911\n",
      "    positive       0.77      0.74      0.75     29798\n",
      "\n",
      "    accuracy                           0.75     56709\n",
      "   macro avg       0.75      0.75      0.75     56709\n",
      "weighted avg       0.75      0.75      0.75     56709\n",
      "\n",
      "==========\n",
      "n_features = 300000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.76      0.74     26880\n",
      "    positive       0.77      0.74      0.75     29829\n",
      "\n",
      "    accuracy                           0.75     56709\n",
      "   macro avg       0.75      0.75      0.75     56709\n",
      "weighted avg       0.75      0.75      0.75     56709\n",
      "\n",
      "==========\n",
      "n_features = 400000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.76      0.74     26889\n",
      "    positive       0.77      0.74      0.76     29820\n",
      "\n",
      "    accuracy                           0.75     56709\n",
      "   macro avg       0.75      0.75      0.75     56709\n",
      "weighted avg       0.75      0.75      0.75     56709\n",
      "\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "n_features = [10, 100, 1000, 10000, 100000, 200000, 300000, 400000]\n",
    "for n in n_features:\n",
    "    vectorizer = HashingVectorizer(n_features=n,)\n",
    "    bow = vectorizer.fit_transform(x_train)\n",
    "    clf = LogisticRegression(random_state=42)\n",
    "    clf.fit(bow, y_train)\n",
    "    pred = clf.predict(vectorizer.transform(x_test))\n",
    "    print(f'n_features = {n}')\n",
    "    print(classification_report(pred, y_test))\n",
    "    print(10*'=')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переобучение не возникает, оптимальное n_features = 200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "gJABxhalLVQu",
    "IaQMCGHFLVQ6",
    "5AJk1B39LVRP",
    "RJlvqWuALVRs",
    "rck5OVqhLVSA",
    "mV3fmzp-LVSU",
    "H5THCOjMLVSg",
    "02s2Vh7MLVSj",
    "b1khxRFDLVSm",
    "sfUmWcAQLVSt",
    "BxvtN-3zLVS5",
    "gyrHhYkgLVTB"
   ],
   "name": "sem1_intro_common.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
