{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLqse9g9pH2r"
   },
   "source": [
    "# Курсовой проект «Введение в обработку естественного языка» "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4GK71CojpH25"
   },
   "source": [
    "## <font color='red'>2. Чат-бот. Реализация.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xsiarsF_phOo",
    "outputId": "20b24eb9-dc4e-40b7-913a-ddfd9099d780"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 4.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.96\n"
     ]
    }
   ],
   "source": [
    "# !pip install pymorphy2\n",
    "# !pip install stop_words\n",
    "\n",
    "# !pip install annoy\n",
    "# !pip install telegram\n",
    "# !pip uninstall python-telegram-bot telegram\n",
    "# !pip install python-telegram-bot --upgrade\n",
    "# !pip install google-cloud-dialogflow\n",
    "\n",
    "# !pip install python-telegram-bot==13.8\n",
    "# !pip install python-telegram-bot --upgrade\n",
    "# !pip install transformers \n",
    "# !pip install transformers sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rqAn-IjDpH28"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import pickle\n",
    "from stop_words import get_stop_words\n",
    "import string\n",
    "from gensim.models import FastText\n",
    "import annoy\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from functools import lru_cache\n",
    "\n",
    "from telegram import Update\n",
    "from telegram.ext import Updater, CommandHandler, MessageHandler, Filters, CallbackContext\n",
    "\n",
    "import logging\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "xDuwJ4HQN9vP"
   },
   "outputs": [],
   "source": [
    "from google.api_core.exceptions import InvalidArgument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F5cg2JnTpZKP",
    "outputId": "ca1b4eb4-89df-4298-fa20-f356d84f763e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QsT02_6DpH3C"
   },
   "outputs": [],
   "source": [
    "morpher = MorphAnalyzer()\n",
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "hUHulgPxpH3E"
   },
   "outputs": [],
   "source": [
    "# Путь к моделям\n",
    "PATH_MODEL = \"models/\"\n",
    "PATH_MODEL = \"/content/drive/MyDrive/Colab Notebooks/nlp/models/\"\n",
    "# Размер эмбеддинга\n",
    "SIZE_EMB = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L3GWNXsxpH3G"
   },
   "source": [
    "##### 2.1. Загрузка моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "GMZ9ix9rpH3I"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(f'{PATH_MODEL}idfs.pkl', 'rb') as f:\n",
    "        idfs = pickle.load(f)\n",
    "\n",
    "    with open(f'{PATH_MODEL}midf.pkl', 'rb') as f:\n",
    "        midf = pickle.load(f)\n",
    "\n",
    "\n",
    "    with open(f'{PATH_MODEL}idfs_prod.pkl', 'rb') as f:\n",
    "        idfs_prod = pickle.load(f)\n",
    "\n",
    "    with open(f'{PATH_MODEL}midf_prod.pkl', 'rb') as f:\n",
    "        midf_prod = pickle.load(f)\n",
    "\n",
    "    modelFT = FastText.load(f'{PATH_MODEL}modelFT')\n",
    "\n",
    "\n",
    "    ft_index = annoy.AnnoyIndex(SIZE_EMB, 'angular')\n",
    "    ft_index.load(f'{PATH_MODEL}index_ft') \n",
    "    with open(f'{PATH_MODEL}index_map_ft.pkl', 'rb') as f:\n",
    "        index_map = pickle.load(f)\n",
    "\n",
    "    vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "    with open(f'{PATH_MODEL}vectorizer.pkl', 'rb') as f:\n",
    "        vectorizer = pickle.load(f)\n",
    "\n",
    "    lr = LogisticRegression()\n",
    "    with open(f'{PATH_MODEL}lr.pkl', 'rb') as f:\n",
    "        lr = pickle.load(f)\n",
    "\n",
    "    with open(f'{PATH_MODEL}midf_prod.pkl', 'rb') as f:\n",
    "        midf_p = pickle.load(f)\n",
    "\n",
    "    ft_index_shop = annoy.AnnoyIndex(SIZE_EMB, 'angular')\n",
    "    ft_index_shop.load(f'{PATH_MODEL}ft_index_shop') \n",
    "\n",
    "    with open(f'{PATH_MODEL}index_map_shop.pkl', 'rb') as f:\n",
    "        index_map_shop = pickle.load(f)\n",
    "\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vMjn-r2itrKK"
   },
   "source": [
    "### Предобработка текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "CXllGenEthko"
   },
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=128, typed=False)\n",
    "\n",
    "def parse_morpher(text):\n",
    "    return morpher.parse(text)[0].normal_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "l3RKhEqituVi"
   },
   "outputs": [],
   "source": [
    "def preprocess_txt(line):\n",
    "    spls = \"\".join(i for i in line.strip() if i not in exclude).split()\n",
    "    spls = [parse_morpher(re.sub(r'\\<[^>]*\\>', '', i).lower()) for i in spls]\n",
    "    spls = [i for i in spls if i not in sw and i != \"\"]\n",
    "    return spls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8TQnuOODt9Wb"
   },
   "outputs": [],
   "source": [
    "def embed_txt(txt, idfs, model, midf):\n",
    "    n_ft = 0\n",
    "    vector_ft = np.zeros(SIZE_EMB)\n",
    "    for word in txt:\n",
    "        if word in model:\n",
    "            vector_ft += model[word] * idfs.get(word, midf)  #\n",
    "            n_ft += idfs.get(word, midf)\n",
    "    if n_ft > 0:\n",
    "        vector_ft = vector_ft / n_ft\n",
    "        \n",
    "    return vector_ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dPQH8ltjvFzf"
   },
   "source": [
    "##### 2.2. Чат-бот"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "kg2P9yPj8NS7"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Dp3P87BFPwGR"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from telegram import Update\n",
    "from telegram.ext import Updater, CommandHandler, MessageHandler, Filters, CallbackContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "VHCtjQ1V4a9-"
   },
   "outputs": [],
   "source": [
    "# !pip install python-telegram-bot --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Dz08dWDBZ7ZE"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from transformers import MBartTokenizer, MBartForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f373nuHvomFa"
   },
   "outputs": [],
   "source": [
    "model_name = \"IlyaGusev/mbart_ru_sum_gazeta\"\n",
    "tokenizer = MBartTokenizer.from_pretrained(model_name)\n",
    "model_mbart_ru_sum_gazeta = MBartForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7JEVTfmuvmQE",
    "outputId": "e9382095-a1c4-4f16-ce04-5b2b43a9d688"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/convert_slow_tokenizer.py:435: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  \"The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option\"\n"
     ]
    }
   ],
   "source": [
    "model_name = \"csebuetnlp/mT5_multilingual_XLSum\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model_mT5_multilingual_XLSum = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "0_bagkrjUQu-"
   },
   "outputs": [],
   "source": [
    "updater = Updater(\" \", use_context=True)  # Токен API к Telegram\n",
    "\n",
    "def echo(update: Update, context: CallbackContext):\n",
    "    txt = update.message.text\n",
    "    update.message.reply_text('Ваше сообщение! ' + update.message.text)\n",
    "\n",
    "\n",
    "def startCommand(update: Update, context: CallbackContext) -> None:\n",
    "    update.message.reply_text('Hi!')\n",
    "\n",
    "def model_mT5_multilingual_XLSum_summary(input_text, model, tokenizer): \n",
    "\n",
    "    WHITESPACE_HANDLER = lambda k: re.sub('\\s+', ' ', re.sub('\\n+', ' ', k.strip()))\n",
    "\n",
    "    input_ids = tokenizer(\n",
    "        [WHITESPACE_HANDLER(input_text)],\n",
    "        return_tensors=\"pt\",\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )[\"input_ids\"]\n",
    "\n",
    "    output_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        max_length=84,\n",
    "        no_repeat_ngram_size=2,\n",
    "        num_beams=4\n",
    "    )[0]\n",
    "\n",
    "    summary = tokenizer.decode(\n",
    "        output_ids,\n",
    "        skip_special_tokens=True,\n",
    "        clean_up_tokenization_spaces=False\n",
    "    )\n",
    "\n",
    "    return summary\n",
    "\n",
    "def textMessage(update: Update, context: CallbackContext) -> None:\n",
    "    input_text = update.message.text\n",
    "    if input_text.split(' ', 1)[0] == 'Summarisation:':\n",
    "\n",
    "        input_text = input_text.replace('Summarisation:', '')\n",
    "        summary = model_mT5_multilingual_XLSum_summary(input_text, \\\n",
    "                                                     model_mT5_multilingual_XLSum, tokenizer)\n",
    "        update.message.reply_text('Суммаризация: ' + summary)\n",
    "\n",
    "    else:\n",
    "        res_text = 'Не понимаю запрос. Сформулируйте запрос иначе.'\n",
    "        input_txt = preprocess_txt(update.message.text)\n",
    "        vect = vectorizer.transform([\" \".join(input_txt)])\n",
    "        prediction = lr.predict(vect)\n",
    "      \n",
    "        if prediction[0] == 1:\n",
    "            find = False\n",
    "            vect_ft = embed_txt(input_txt, idfs_prod, modelFT, midf_prod)\n",
    "            ft_index_shop_val, distances_shop = ft_index_shop.get_nns_by_vector(vect_ft, 3, include_distances=True)\n",
    "            for i, item in enumerate(ft_index_shop_val):\n",
    "                if distances_shop[i] <= 0.3:          \n",
    "                    title, image = index_map_shop[item]\n",
    "                    print(title, image)\n",
    "                    update.message.reply_text(\"title: {} image: {}\".format(title, image))\n",
    "                    find = True\n",
    "            if find == False:\n",
    "                update.message.reply_text(res_text)\n",
    "        else:\n",
    "            vect_ft = embed_txt(input_txt, idfs, modelFT, midf)\n",
    "            ft_index_val, distances = ft_index.get_nns_by_vector(vect_ft, 1, include_distances=True)\n",
    "            if distances[0] <= 0.3:\n",
    "                update.message.reply_text(index_map[ft_index_val[0]])\n",
    "            else:\n",
    "                update.message.reply_text(res_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "lK8mS0CZ_ajj"
   },
   "outputs": [],
   "source": [
    "dispatcher = updater.dispatcher\n",
    "\n",
    "dispatcher.add_handler(CommandHandler('start', startCommand))\n",
    "dispatcher.add_handler(MessageHandler(Filters.text & ~Filters.command, textMessage))\n",
    "\n",
    "updater.start_polling()\n",
    "updater.idle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CGEgZXFD4dpk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JxTjGrsp4dtF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mYRTX9upu-fH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xxlFiFO1y7dh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "course_prj_bot.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
