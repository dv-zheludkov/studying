{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тема “Генерация текстов (языковое моделирование)”\n",
    "\n",
    "Разобраться с моделькой генерации текста, собрать самим или взять датасет с вебинара и обучить генератор текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 09:54:52.906678: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('evgenyi_onegin.txt', 'rb').read().decode(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 286984 characters\n"
     ]
    }
   ],
   "source": [
    "print('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Александр Сергеевич Пушкин\n",
      "\n",
      "                                Евгений Онегин\n",
      "                                Роман в стихах\n",
      "\n",
      "                        Не мысля гордый свет забавить,\n",
      "                        Вниманье дружбы возлюбя,\n",
      "                        Хотел бы я тебе представить\n",
      "                        Залог достойнее тебя,\n",
      "                        Достойнее души прекрасной,\n",
      "                        Святой исполненной мечты,\n",
      "                        Поэзии живой и ясной,\n",
      "                        Высоких дум и простоты;\n",
      "                        Но так и быть - рукой пристрастной\n",
      "                        Прими собранье пестрых глав,\n",
      "                        Полусмешных, полупечальных,\n",
      "                \n"
     ]
    }
   ],
   "source": [
    "print(text[:700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 unique characters\n"
     ]
    }
   ],
   "source": [
    "print('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Александр Сергеевич Пушкин\n",
      "\n",
      "                                Евгений Онегин\n",
      "                                Роман в стихах\n",
      "\n",
      "                        Не мысля гордый свет забавить,\n",
      "                      \n",
      "[ 71 110 104 109 116  99 112 103 115   1  87 104 115 102 104 104 101 107\n",
      " 122   1  85 118 123 109 107 112   0   0   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1  76 101 102 104 112 107 108   1  84 112 104 102\n",
      " 107 112   0   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1  86\n",
      " 113 111  99 112   1 101   1 116 117 107 120  99 120   0   0   1   1   1\n",
      "   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
      "   1   1   1  83 104   1 111 126 116 110 130   1 102 113 115 103 126 108\n",
      "   1 116 101 104 117   1 106  99 100  99 101 107 117 127   7   0   1   1\n",
      "   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
      "   1   1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(text[:200]), print(text_as_int[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 09:54:57.633360: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//(seq_length+1)\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "А\n",
      "л\n",
      "е\n",
      "к\n",
      "с\n",
      "а\n",
      "н\n",
      "д\n",
      "р\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for i in char_dataset.take(10):\n",
    "    print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Александр Сергеевич Пушкин\\n\\n                                Евгений Онегин\\n                          '\n",
      "'      Роман в стихах\\n\\n                        Не мысля гордый свет забавить,\\n                        '\n",
      "'Вниманье дружбы возлюбя,\\n                        Хотел бы я тебе представить\\n                        '\n",
      "'Залог достойнее тебя,\\n                        Достойнее души прекрасной,\\n                        Свят'\n",
      "'ой исполненной мечты,\\n                        Поэзии живой и ясной,\\n                        Высоких д'\n"
     ]
    }
   ],
   "source": [
    "for item in sequences.take(5):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'Александр Сергеевич Пушкин\\n\\n                                Евгений Онегин\\n                         '\n",
      "Target data: 'лександр Сергеевич Пушкин\\n\\n                                Евгений Онегин\\n                          '\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "    print('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                                  batch_input_shape=[batch_size, None]),\n",
    "                                 \n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "\n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "\n",
    "         tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        \n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "                                   \n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 131) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (64, None, 256)           33536     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (64, None, 1024)          5246976   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (64, None, 1024)          8392704   \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (64, None, 1024)          8392704   \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (64, None, 1024)          8392704   \n",
      "                                                                 \n",
      " dense (Dense)               (64, None, 131)           134275    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,592,899\n",
      "Trainable params: 30,592,899\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1) #количество независимых выборок 1\n",
    "\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 61, 116, 127, 120,  11,   4,  47, 128,  19,  83,  75,  53, 105,\n",
       "        34, 122,  63, 118,  42,  84,  94,  81, 118, 110,  51, 123,  40,\n",
       "        25,  60,  69,  31,  90,   0,  83,  11,  64,  24,  46,  77, 101,\n",
       "        99,  73,  13,   2,  81,  25,  82,  17,   0,  90,  36,  26,  64,\n",
       "        11, 127,   6,  84,  74, 113,  86,   7,  98,  70, 117,  60,   3,\n",
       "       117,  15,  85,  91,  62,  57,  59,  43,  56,  13,  99,  70, 105,\n",
       "        47,   0, 109,  73, 125, 102,  93,  15, 115,  59,  10,  44,  37,\n",
       "        30,  26,  75, 127,  35,  62,  35, 112,  13])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " 'Того раскаянье грызет.\\n                        Все это часто придает\\n                        Большую'\n",
      "\n",
      "Next Char Predictions: \n",
      " 'rсьх1\\'cэ9НДiжNчtуWОШЛулgшTCq{IФ\\nН1uBbЖваВ3!ЛCМ7\\nФPDu1ь)ОГоР,Я}тq\"т5ПХsnpXm3а}жc\\nкВъгЧ5рp0YQHDДьOsOн3'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "\n",
    "print(\"\\nNext Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss = loss(target_example_batch, example_batch_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 131)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       4.874953\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_freq=100*5,\n",
    "    save_weights_only=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "44/44 [==============================] - 387s 9s/step - loss: 2.4698\n",
      "Epoch 2/40\n",
      "44/44 [==============================] - 388s 9s/step - loss: 2.2311\n",
      "Epoch 3/40\n",
      "44/44 [==============================] - 370s 8s/step - loss: 1.9328\n",
      "Epoch 4/40\n",
      "44/44 [==============================] - 391s 9s/step - loss: 1.7538\n",
      "Epoch 5/40\n",
      "44/44 [==============================] - 388s 9s/step - loss: 1.6703\n",
      "Epoch 6/40\n",
      "44/44 [==============================] - 391s 9s/step - loss: 1.5713\n",
      "Epoch 7/40\n",
      "44/44 [==============================] - 389s 9s/step - loss: 1.4959\n",
      "Epoch 8/40\n",
      "44/44 [==============================] - 388s 9s/step - loss: 1.4455\n",
      "Epoch 9/40\n",
      "44/44 [==============================] - 378s 9s/step - loss: 1.4123\n",
      "Epoch 10/40\n",
      "44/44 [==============================] - 379s 9s/step - loss: 1.3901\n",
      "Epoch 11/40\n",
      "44/44 [==============================] - 397s 9s/step - loss: 1.3669\n",
      "Epoch 12/40\n",
      "44/44 [==============================] - 392s 9s/step - loss: 1.3486\n",
      "Epoch 13/40\n",
      "44/44 [==============================] - 396s 9s/step - loss: 1.3328\n",
      "Epoch 14/40\n",
      "44/44 [==============================] - 394s 9s/step - loss: 1.3150\n",
      "Epoch 15/40\n",
      "44/44 [==============================] - 390s 9s/step - loss: 1.3160\n",
      "Epoch 16/40\n",
      "44/44 [==============================] - 367s 8s/step - loss: 1.2894\n",
      "Epoch 17/40\n",
      "44/44 [==============================] - 353s 8s/step - loss: 1.2827\n",
      "Epoch 18/40\n",
      "44/44 [==============================] - 690s 16s/step - loss: 1.2905\n",
      "Epoch 19/40\n",
      "44/44 [==============================] - 383s 9s/step - loss: 1.2690\n",
      "Epoch 20/40\n",
      "44/44 [==============================] - 392s 9s/step - loss: 1.2474\n",
      "Epoch 21/40\n",
      "44/44 [==============================] - 390s 9s/step - loss: 1.2660\n",
      "Epoch 22/40\n",
      "44/44 [==============================] - 374s 8s/step - loss: 1.2361\n",
      "Epoch 23/40\n",
      "44/44 [==============================] - 384s 9s/step - loss: 1.2152\n",
      "Epoch 24/40\n",
      "44/44 [==============================] - 372s 8s/step - loss: 1.1994\n",
      "Epoch 25/40\n",
      "44/44 [==============================] - 362s 8s/step - loss: 1.2099\n",
      "Epoch 26/40\n",
      "44/44 [==============================] - 372s 8s/step - loss: 1.2037\n",
      "Epoch 27/40\n",
      "44/44 [==============================] - 361s 8s/step - loss: 1.1830\n",
      "Epoch 28/40\n",
      "44/44 [==============================] - 355s 8s/step - loss: 1.1607\n",
      "Epoch 29/40\n",
      "44/44 [==============================] - 2368s 55s/step - loss: 1.1488\n",
      "Epoch 30/40\n",
      "44/44 [==============================] - 1274s 29s/step - loss: 1.1388\n",
      "Epoch 31/40\n",
      "44/44 [==============================] - 741s 16s/step - loss: 1.1214\n",
      "Epoch 32/40\n",
      "44/44 [==============================] - 363s 8s/step - loss: 1.1014\n",
      "Epoch 33/40\n",
      "44/44 [==============================] - 366s 8s/step - loss: 1.0779\n",
      "Epoch 34/40\n",
      "44/44 [==============================] - 367s 8s/step - loss: 1.1111\n",
      "Epoch 35/40\n",
      "44/44 [==============================] - 405s 9s/step - loss: 1.0848\n",
      "Epoch 36/40\n",
      "44/44 [==============================] - 367s 8s/step - loss: 1.0577\n",
      "Epoch 37/40\n",
      "44/44 [==============================] - 362s 8s/step - loss: 1.0509\n",
      "Epoch 38/40\n",
      "44/44 [==============================] - 376s 9s/step - loss: 1.0270\n",
      "Epoch 39/40\n",
      "44/44 [==============================] - 395s 9s/step - loss: 1.0078\n",
      "Epoch 40/40\n",
      "44/44 [==============================] - 404s 9s/step - loss: 0.9957\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 40\n",
    "history = model.fit(dataset, epochs=num_epoch, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./training_checkpoints/ckpt_35'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (1, None, 256)            33536     \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (1, None, 1024)           5246976   \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (1, None, 1024)           8392704   \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (1, None, 1024)           8392704   \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (1, None, 1024)           8392704   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (1, None, 131)            134275    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,592,899\n",
      "Trainable params: 30,592,899\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "  \n",
    "    num_generate = 1000\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    text_generated = []\n",
    "\n",
    "    temperature = 0.8\n",
    "\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        \n",
    "        predictions = model(input_eval)\n",
    "       \n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ = generate_text(model, start_string=u\"И вот идет уже \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "И вот идет уже еодуоооимеяояо.   таааоиииа ;, ,  \n",
      "\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "                                                         XXII\n",
      "\n",
      "                                             Не в приетны послевает:\n",
      "                                                         LV\n",
      "\n",
      "                         Снег преизбают;\n",
      "                              Тан? Продитла я ветелся,\n",
      "                                            XVII\n",
      "\n",
      "                                                XXXV\n",
      "\n",
      "                                                            Татьяны модя подел,\n",
      "                                Дужен вер                         LIII\n",
      "\n",
      "                           Не приврестный долде. Вдольней скутой\n",
      "                               Конь он он полного ильной,\n",
      "                          И это под покревить, к там ро тобой\n",
      "                                                                 В мы, что и ручи умачит\n",
      "                                       Не полнал жену возбо                             Но можалы роченский други,\n",
      "                      \n"
     ]
    }
   ],
   "source": [
    "print(text_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, без тщательной подгонки параметров генерации результат получается достаточно своеобразный"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "gJABxhalLVQu",
    "IaQMCGHFLVQ6",
    "5AJk1B39LVRP",
    "RJlvqWuALVRs",
    "rck5OVqhLVSA",
    "mV3fmzp-LVSU",
    "H5THCOjMLVSg",
    "02s2Vh7MLVSj",
    "b1khxRFDLVSm",
    "sfUmWcAQLVSt",
    "BxvtN-3zLVS5",
    "gyrHhYkgLVTB"
   ],
   "name": "sem1_intro_common.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
